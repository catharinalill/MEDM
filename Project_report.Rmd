---
title: "Project MEDM"
output: html_document
        #pdf_document
---

<!-- Press Knit, to make a html-file of the code below. This we can use while working with the report to see how it is. Because the dataset flights in pretty large it takes some time to knit the file.. 
We don´t have to compilate the code to a pdf before we are delivering it, but if you want to you might have to download a program, maybe Latex or something, I am not quite sure. I already have it so I can compilate it to a pdf when we are done with it. 
But remember if you compilate it to a pdf-file some lines can be too long and get cutted. Then you have to go in the code and adjust it. If you need a linespace you need to have 3 space in the line above. -->

<!-- In gitkranken: 
When you have edited the code, save it usual. Then open gitkranken, and you will see a blue line with 
" x file changes in working directory" and a small box "View changes" in the above right corner. Click this one. First you have to commit what you have done, i.e. click on the Project_report.html-file on the right side and press Stage File. (And don´t stage all the other files) Then make a comment on what you have changed in the file, in the bottom right corner, and press the green box "Stage files/changes to commit". 
After commiting you first have to pull what the other have done, i.e. press "Pull". If you get "pulled successfully" down in the left corner everything is okay and you can press "Push". 
If not, then we might have some merge conflict we need to fix. 
Always remember to do all these steps
1. Commit
2. Pull
3. Push

If you have edited the file, but don´t want to save it, only download what the others have done, you can press the "Stash" instead of pull and push. 
-->

```{r setup, include=FALSE}
#Have to include the files in the same folder the Rmarkdown is in.
airlines = read.csv("airlines.csv")
airports = read.csv("airports.csv")
flights = read.csv("flights.csv")

```

   
```{r echo = FALSE}  
 #to prevent the code chunk from printing of the R code

```

<!-- This is a comment. -->

<!--
Here we can write Latex code, with formulas inline $E=mc^2$, or in a new line,
$$
    A = \pi \cdot r^2.
$$
This is standard Latex-code, so we can write all mathematical signs by using $\mathbf{A}x = b$. 
$\hat{Y}$, $Y_i$, $\theta$, $\rho(X,C)$, $x_1^{(1)}$. 
\textbf{bold text}, \textit{italicized}
This link includes a list of mathematical symbols written in latex. https://oeis.org/wiki/List_of_LaTeX_mathematical_symbols
-->

   <!-- 1 # means Section  -->
# PART 1: EXPLORATORTY DATA ANALYSIS 

 <!-- Perform a exploratory data analysis and discuss what you have learned from this analysis.
 
 
 Aim: Which airline should we fly on? 
 
The U.S. Department of Transportation's (DOT) Bureau of Transportation Statistics tracks the on-time performance of domestic flights operated by large air carriers. 
Summary information on the number of on-time, delayed, canceled, and diverted flights is published in DOT's monthly Air Travel Consumer Report and in this dataset of 2015 flight delays and cancellations.

Initial steps: 
1-	To solve the classification problem the group must create a new variable through the analysis of the variables associated to the delay that can be used as response variable for the problem aim. 
 
 -->


```{r , echo=TRUE}
library(ggplot2)  #for ggplot
library(class)    #for confusion matrices
library(caret)    #for knn function
library(GGally)
library(corrplot)
library(MASS)     #for LDA
library(leaps)    #for Forward selection
#NEED TO CREATE RESPONSE VARIABLE HERE


#The first variable in our flights dataset is YEAR = 2015, which is equal for all so we should not include
# this in the data analysis/classification.

#DATA ANALYSIS

#plot_str(flights[,c(2:10)]) #When we have found the response variable add this: c(2:10,response variable)

#Search for missing values
plot_missing(flights)

#Continuous variables
#plot_histogram(flights[,2:10])
#plot_density(flights[,2:10])

#Correlation
plot_correlation((flights[, 2:31]), type = "continuous")
#or
#corrplot(cor(flights),method = "circle")

#plot_bar(flights)

#Check the response variable, plot a histogram and see the distribution, could us qqplot
#ggplot(data = flights)

#library(DataExplorer)
#create_report(flights)
#Check for outliers
#boxplot(flights[,1]~flights[,101], col=c(1:2))
```


```{r , echo=TRUE}
#Create another data variable

##Remove the observations for which the flight was cancelled
handled_flights <- flights[flights$CANCELLED<1,]
#Remove columns YEAR (2015 for all observations), CANCELLATION_REASON (since we are now dealing with flights that 
#were not cancelled), CANCELLED (will have 0's since these are the flights that were not cancelled)
#and DIVERTED (will have 0's, non of the non cancelled flights was diverted)
handled_flights$YEAR <- NULL
handled_flights$CANCELLATION_REASON <- NULL
handled_flights$CANCELLED <- NULL
handled_flights$DIVERTED <- NULL

#Erase columns which have NA for some observations
handled_flights$AIR_SYSTEM_DELAY <- NULL
handled_flights$SECURITY_DELAY <- NULL
handled_flights$AIRLINE_DELAY <- NULL
handled_flights$LATE_AIRCRAFT_DELAY <- NULL
handled_flights$WEATHER_DELAY <- NULL

#Erase the observations for which there was no information concerning the arrival delay
handled_flights<- handled_flights[is.na(handled_flights$ARRIVAL_DELAY)==FALSE,]

#Create new column (DELAY: 0 if the flight is not delayed by more than 5 minutes, 1 if the flight is delayed by more than 5 minutes) 
#Here we consider only the arrival delay  (THIS CHOICE SHOULD BE JUSTIFIED IN THE REPORT!)

handled_flights$DELAY <- ifelse(handled_flights$ARRIVAL_DELAY > 5,handled_flights$DELAY <- 1,handled_flights$DELAY <- 0)

#Try to remove some columns (here I used only 2, but then R gives an error, when doing k-fold
#becuase it thinks I am doing regression...)


#Need to do variable selection here
#Try Forward Selection
regfit.full = regsubsets(DELAY~.,data = handled_flights,method = "forward")
reg.summary = summary(regfit.full)

#Plot adjusted R^2, C_p and BIC for all the models at once
par(mfrow =c(3,2))

plot(reg.summary$adjr2,xlab="Number of Variables", ylab = "Adjusted RSq", type = "1")
adjr2_max = which.max(reg.summary$adjr2)
points(adjr2_max, reg.summary$adjr2[adjr2_max], col = "red", cex = 2, pch = 20)

plot(reg.summary$bic,xlab="Number of Variables", ylab = "BIC", type = "1")
bic_min = which.min(reg.summary$bic)
points(bic_min, reg.summary$bic[bic_min], col = "red", cex = 2, pch = 20)

plot(reg.summary$cp,xlab="Number of Variables", ylab = "Cp", type = "1")
cp_min = which.min(reg.summary$cp)
points(cp_min, reg.summary$cp[cp_min], col = "red", cex = 2, pch = 20)

#From this we can choose the "best" model and use this subset of variables to do the classification



#Need to have a larger subset of varibales here
#Use only the 4th and 23th columns (Airline, Delay)
handled_flights2 <- handled_flights[c(4,23)]

############## Another approach ####################################

#Add all delay variables to see if the trip in total are delayed or not
#flights$TOTAL_DELAY <- flights$DEPARTURE_DELAY + flights$ARRIVAL_DELAY

#Make new variable delayed (yes/no)
#ifelse(flights$TOTAL_DELAY > 0,flights$DELAYED <- 1,flights$DELAYED <- 0)


```



# PART 2: SOLVE CLASSIFICATION PROBLEM

 <!-- Solve your classification problem.  Consider several classification methods and discuss  how  can  they  contribute  for  the  solution  of  your  problem.   Include in your discussion topics such as the options that you have made in building each  classifier;  interpretation  of  results;  validation  of  the  methods  used  and possible assumptions;  advantages and disadvantages of each alternative;  etc. Have  in  mind  that  some  of  the  explanatory  variables  may  be  irrelevant  to the  classification problem and that  you may need to  do  some  preprocessing methodologies of your data set e.g.  dimensionality reduction techniques.-->

```{r , echo=TRUE}


```
 <!-- 2 ## means subsection, 3 means subsubsection etc.-->   

## Naive Bayes method

```{r , echo=TRUE}


```

## KNN

```{r , echo=TRUE}


``` 

    
## Resubstitution

```{r , echo=TRUE}


```


## Hold Out method

```{r , echo=TRUE}


```
The training and test set will be dependent on which observations are included in each of them and this could lead to high variability of validation set error. Another disadvantage with hold out method is that due to dividing the training set in two, the sample size for model fitting will be smaller. 

## LOOCV

```{r , echo=TRUE}


```
The advantages with LOOCV is that there is no randomsness in splitting the data into training and test set. There is also little bias since nearly the whole data set is used for training, compared to only half the data set for Hold Out method Further, one disadvantage with LOOCV is the expensive implementation because we need to fit $n$ different models. Due to quite similar training sets, since they only differ by one observation, each fold will be highly correlated and this could give high variance for the LOOCV approach as well. 
   
## K-fold CV

```{r , echo=TRUE}
# Spliting data as training and test set using createDataPartition() function from caret
indxTrain <- createDataPartition(y = handled_flights2[,23], p = 0.8,list = FALSE)
train.data <- handled_flights2[indxTrain,]
test.data <- handled_flights2[-indxTrain,]

train.control <- trainControl(method = "cv",number = 10) 
# Train the model
set.seed(0) # To fix the random process at splitting data
pred.knn.cv <- train(CL~.,
                     method     = "knn",
                     tuneGrid   = expand.grid(k = 1:20),
                     trControl  = train.control,
                     metric     = "Accuracy",
                     data       = cbind(CL = as.factor(train.data[,23]), train.data[,-23]))
#Error: vector memory exhausted (limit reached?)


# Summarize the results
print(pred.knn.cv)
plot(pred.knn.cv)

# Prediction of fitted model
fit_cv <- predict(pred.knn.cv,newdata = test.data)

# Make confusion matrix 
confusionMatrix(test.data$y, fit_cv)

# Calculate accuracy
mean(test.data$y == fit_cv)

# Calculate misclassification error 
mean(test.data$y != fit_cv)


```

One disadvantage with using K-fold cross validation is that the result may vary according to how the folds are made. Since the training set is $(k-1)/k$ of the original data set, this will give an estimate of the prediction error that is biased upwards. 

One advantage with cross validation over the LOOCV approach is that there is less computational work when we have $k=10$, instead of $K=N$. 
By considering the Bias-Variance trade-off we have smaller variance for the CV approach than the LOOCV, but again LOOCV has smaller bias. 


## Repeated K-fold CV

```{r , echo=TRUE}
train.control <- trainControl(method = "repeatedcv", 
                              number = 5, repeats = 4)
set.seed(0)
pred.knn.rcv <- train(CL~.,
                     method     = "knn",
                     tuneGrid   = expand.grid(k = 1:20),
                     trControl  = train.control,
                     metric     = "Accuracy",
                     data       = cbind(CL = as.factor(train.data[,23]), train.data[,-23]))
# Summarize the results
print(pred.knn.rcv)
plot(pred.knn.rcv)

# Prediction of fitted model
fit_rcv <- predict(pred.knn.rcv,newdata = test.data)

# Make confusion matrix 
confusionMatrix(test.data$y, fit_rcv)

# Calculate accuracy
mean(test.data$y == fit_rcv)

# Calculate misclassification error 
mean(test.data$y != fit_rcv)

```



## Bootstrap

```{r , echo=TRUE}


```



# PART 3: LEARNING/LIMITATIONS/FUTURE WORK

 <!-- Imagine you are going to meet the researcher who contacted you.  Report to him/her what you have learned about the problem.  Discuss limitations of the analysis you have done and provide suggestions for future work.-->


```{r , echo=TRUE}


```

